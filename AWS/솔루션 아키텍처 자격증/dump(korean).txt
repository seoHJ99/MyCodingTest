1.
회사는 여러 대륙의 도시에서 온도, 습도 및 기압 데이터를 수집하고 있습니다. 각 사이트에서 일일 평균 500GB의 데이터를 수집합니다. 각 사이트는 고속 인터넷 연결을 보유하고 있습니다.
회사는 이러한 전 세계 사이트의 데이터를 가능한 한 빨리 단일 Amazon S3 버킷으로 집계하고자 합니다. 솔루션은 운영 복잡성을 최소화해야 합니다.
이 요구사항을 충족하는 솔루션은 무엇입니까?

A. 대상 S3 버킷에서 S3 Transfer Acceleration을 활성화합니다. 멀티파트 업로드를 사용하여 사이트 데이터를 대상 S3 버킷으로 직접 업로드합니다.
B. 각 사이트에서 가장 가까운 리전의 S3 버킷으로 데이터를 업로드합니다. S3 Cross-Region Replication을 사용하여 객체를 대상 S3 버킷으로 복사합니다. 그런 다음 원본 S3 버킷에서 데이터를 제거합니다.
C. 매일 AWS Snowball Edge Storage Optimized 디바이스 작업을 예약하여 각 사이트에서 가장 가까운 리전으로 데이터를 전송합니다. S3 Cross-Region Replication을 사용하여 객체를 대상 S3 버킷으로 복사합니다.
D. 각 사이트에서 가장 가까운 리전의 Amazon EC2 인스턴스로 데이터를 업로드합니다. 데이터를 Amazon Elastic Block Store (Amazon EBS) 볼륨에 저장합니다. 정기적으로 EBS 스냅샷을 찍어 대상 S3 버킷이 있는 리전으로 복사합니다. 해당 리전에서 EBS 볼륨을 복원합니다.
(a)

2.
회사는 독점 애플리케이션의 로그 파일을 분석할 수 있어야 합니다. 로그는 JSON 형식으로 Amazon S3 버킷에 저장되어 있습니다. 쿼리는 간단하며 필요할 때 실행됩니다. 솔루션 아키텍트는 최소한의 아키텍처 변경으로 분석을 수행해야 합니다.
운영 오버헤드를 최소화하면서 이러한 요구 사항을 충족하기 위해 솔루션 아키텍트는 무엇을 해야 합니까?

A. Amazon Redshift를 사용하여 모든 내용을 한 곳에 로드하고 필요한 SQL 쿼리를 실행합니다.
B. Amazon CloudWatch Logs를 사용하여 로그를 저장합니다. Amazon CloudWatch 콘솔에서 필요한 SQL 쿼리를 실행합니다.
C. Amazon Athena를 직접 Amazon S3와 함께 사용하여 필요한 쿼리를 실행합니다.
D. AWS Glue를 사용하여 로그를 카탈로그화합니다. Amazon EMR에서 일시적인 Apache Spark 클러스터를 사용하여 필요한 SQL 쿼리를 실행합니다.
(c)

3.
회사는 여러 부서의 다양한 AWS 계정을 관리하기 위해 AWS Organizations를 사용합니다. 관리 계정에는 프로젝트 보고서를 포함하는 Amazon S3 버킷이 있습니다. 회사는 이 S3 버킷에 대한 접근을 AWS Organizations 내의 계정 사용자에게만 제한하고자 합니다.
운영 오버헤드를 최소화하면서 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

A. S3 버킷 정책에 조직 ID를 참조하여 aws PrincipalOrgID 글로벌 조건 키를 추가합니다.
B. 각 부서를 위해 조직 단위(OU)를 생성합니다. S3 버킷 정책에 aws
글로벌 조건 키를 추가합니다.
C. AWS CloudTrail을 사용하여 CreateAccount, InviteAccountToOrganization, LeaveOrganization 및 RemoveAccountFromOrganization 이벤트를 모니터링합니다. S3 버킷 정책을 이에 따라 업데이트합니다.
D. S3 버킷에 접근이 필요한 각 사용자에게 태그를 지정합니다. S3 버킷 정책에 aws
글로벌 조건 키를 추가합니다.
(a)

4.
애플리케이션이 VPC 내의 Amazon EC2 인스턴스에서 실행됩니다. 이 애플리케이션은 Amazon S3 버킷에 저장된 로그를 처리합니다. EC2 인스턴스는 인터넷에 연결되지 않고 S3 버킷에 접근해야 합니다.
Amazon S3에 대한 사설 네트워크 연결을 제공할 솔루션은 무엇입니까?

A. S3 버킷에 대한 게이트웨이 VPC 엔드포인트를 생성합니다.
B. 로그를 Amazon CloudWatch Logs로 스트리밍합니다. 로그를 S3 버킷으로 내보냅니다.
C. Amazon EC2에 S3 접근을 허용하는 인스턴스 프로파일을 생성합니다.
D. S3 엔드포인트에 접근하기 위해 프라이빗 링크가 있는 Amazon API Gateway API를 생성합니다.
(a)

5.
회사는 AWS에서 웹 애플리케이션을 호스팅 중이며, 사용자 업로드 문서를 Amazon EBS 볼륨에 저장하고 있습니다. 더 나은 확장성과 가용성을 위해 아키텍처를 복제하여 다른 가용 영역에 두 번째 EC2 인스턴스와 EBS 볼륨을 생성하고, 두 인스턴스를 Application Load Balancer 뒤에 배치했습니다. 이 변경 후, 사용자가 웹사이트를 새로고침할 때마다 문서의 하위 집합만 보게 되며, 한 번에 모든 문서를 볼 수 없습니다.
사용자가 한 번에 모든 문서를 볼 수 있도록 하기 위해 솔루션 아키텍트가 제안해야 할 해결책은 무엇입니까?

A. 데이터를 복사하여 두 EBS 볼륨이 모든 문서를 포함하도록 합니다.
B. Application Load Balancer를 구성하여 사용자가 문서가 있는 서버로 향하게 합니다.
C. 두 EBS 볼륨의 데이터를 Amazon EFS로 복사합니다. 애플리케이션을 수정하여 새 문서를 Amazon EFS에 저장하도록 합니다.
D. Application Load Balancer를 구성하여 요청을 두 서버로 보냅니다. 각 문서를 올바른 서버에서 반환하도록 합니다.
(c)

6.
회사는 온프레미스 네트워크 부착 스토리지에 NFS를 사용하여 큰 비디오 파일을 저장하고 있습니다. 각 비디오 파일의 크기는 1MB에서 500GB까지 다양합니다. 총 스토리지 용량은 70TB이며 더 이상 증가하지 않습니다. 회사는 비디오 파일을 가능한 빨리 Amazon S3로 마이그레이션해야 하며 네트워크 대역폭 사용을 최소화해야 합니다.
이 요구사항을 충족하는 솔루션은 무엇입니까?

A. S3 버킷을 생성합니다. S3 버킷에 쓸 수 있는 권한을 가진 IAM 역할을 생성합니다. AWS CLI를 사용하여 모든 파일을 로컬에서 S3 버킷으로 복사합니다.
B. AWS Snowball Edge 작업을 생성합니다. 온프레미스에 Snowball Edge 장치를 받습니다. Snowball Edge 클라이언트를 사용하여 데이터를 장치로 전송합니다. 장치를 반환하여 AWS가 데이터를 Amazon S3로 가져오도록 합니다.
C. 온프레미스에 S3 파일 게이트웨이를 배포합니다. S3 파일 게이트웨이에 연결하기 위한 공용 서비스 엔드포인트를 생성합니다. S3 버킷을 생성합니다. S3 파일 게이트웨이에 새로운 NFS 파일 공유를 생성합니다. 새 파일 공유를 S3 버킷에 연결합니다. 기존 NFS 파일 공유에서 S3 파일 게이트웨이로 데이터를 전송합니다.
D. 온프레미스 네트워크와 AWS 간에 AWS Direct Connect 연결을 설정합니다. 온프레미스에 S3 파일 게이트웨이를 배포합니다. S3 파일 게이트웨이에 연결하기 위한 공용 가상 인터페이스(VIF)를 생성합니다. S3 버킷을 생성합니다. S3 파일 게이트웨이에 새로운 NFS 파일 공유를 생성합니다. 새 파일 공유를 S3 버킷에 연결합니다. 기존 NFS 파일 공유에서 S3 파일 게이트웨이로 데이터를 전송합니다.
(b)

7.
회사는 들어오는 메시지를 수신하는 애플리케이션을 보유하고 있습니다. 수십 개의 다른 애플리케이션과 마이크로서비스가 이러한 메시지를 빠르게 소비합니다. 메시지의 수는 크게 달라지며 때때로 초당 100,000개로 급증합니다. 회사는 솔루션을 분리하고 확장성을 높이고자 합니다.
이 요구사항을 충족하는 솔루션은 무엇입니까?

A. 메시지를 Amazon Kinesis Data Analytics에 저장합니다. 소비 애플리케이션이 메시지를 읽고 처리하도록 구성합니다.
B. 수신 애플리케이션을 Amazon EC2 인스턴스의 Auto Scaling 그룹에 배포하여 CPU 메트릭을 기준으로 EC2 인스턴스 수를 조정합니다.
C. 메시지를 단일 샤드가 있는 Amazon Kinesis Data Streams에 작성합니다. AWS Lambda 함수를 사용하여 메시지를 전처리하고 Amazon DynamoDB에 저장합니다. 소비 애플리케이션이 DynamoDB에서 메시지를 읽어 처리하도록 구성합니다.
D. 메시지를 여러 Amazon Simple Queue Service (Amazon SQS) 구독이 있는 Amazon Simple Notification Service (Amazon SNS) 주제에 게시합니다. 소비 애플리케이션이 큐에서 메시지를 처리하도록 구성합니다.
(d)

8.
회사는 분산 애플리케이션을 AWS로 마이그레이션하고 있습니다. 이 애플리케이션은 가변적인 워크로드를 처리합니다. 레거시 플랫폼은 주 서버가 여러 컴퓨팅 노드에 작업을 조정하는 방식으로 구성되어 있습니다. 회사는 애플리케이션을 현대화하여 최대한의 탄력성과 확장성을 달성하고자 합니다.
이 요구사항을 충족하기 위해 솔루션 아키텍트는 아키텍처를 어떻게 설계해야 합니까?

A. 작업의 대상으로 Amazon Simple Queue Service (Amazon SQS) 큐를 구성합니다. Auto Scaling 그룹으로 관리되는 Amazon EC2 인스턴스로 컴퓨팅 노드를 구현합니다. EC2 Auto Scaling을 예약된 스케일링을 사용하도록 구성합니다.
B. 작업의 대상으로 Amazon Simple Queue Service (Amazon SQS) 큐를 구성합니다. Auto Scaling 그룹으로 관리되는 Amazon EC2 인스턴스로 컴퓨팅 노드를 구현합니다. 큐의 크기를 기반으로 EC2 Auto Scaling을 구성합니다.
C. Auto Scaling 그룹으로 관리되는 Amazon EC2 인스턴스로 주 서버와 컴퓨팅 노드를 구현합니다. 작업의 대상으로 AWS CloudTrail을 구성합니다. 주 서버의 부하를 기반으로 EC2 Auto Scaling을 구성합니다.
D. Auto Scaling 그룹으로 관리되는 Amazon EC2 인스턴스로 주 서버와 컴퓨팅 노드를 구현합니다. 작업의 대상으로 Amazon EventBridge (Amazon CloudWatch Events)를 구성합니다. 컴퓨팅 노드의 부하를 기반으로 EC2 Auto Scaling을 구성합니다.
(b)

9.
회사는 데이터 센터에서 SMB 파일 서버를 운영 중입니다. 파일 서버는 생성된 후 처음 며칠 동안 자주 접근되는 대용량 파일을 저장합니다. 7일 후에는 파일에 거의 접근하지 않습니다. 총 데이터 크기가 증가하여 회사의 총 저장 용량에 근접하고 있습니다. 솔루션 아키텍트는 최근에 접근한 파일에 대한 저지연 접근을 유지하면서 회사의 사용 가능한 저장 공간을 늘려야 합니다. 또한 파일 수명 주기 관리를 제공하여 미래의 저장 문제를 피해야 합니다.
이 요구사항을 충족하는 솔루션은 무엇입니까?

A. AWS DataSync를 사용하여 7일이 지난 데이터를 SMB 파일 서버에서 AWS로 복사합니다.
B. 회사의 저장 공간을 확장하기 위해 Amazon S3 File Gateway를 생성합니다. 데이터를 7일 후 S3 Glacier Deep Archive로 전환하는 S3 수명 주기 정책을 생성합니다.
C. 회사의 저장 공간을 확장하기 위해 Amazon FSx for Windows File Server 파일 시스템을 생성합니다.
D. 각 사용자의 컴퓨터에 유틸리티를 설치하여 Amazon S3에 접근할 수 있도록 합니다. 데이터를 7일 후 S3 Glacier Flexible Retrieval로 전환하는 S3 수명 주기 정책을 생성합니다.
(b)

10.
회사는 AWS에서 전자상거래 웹 애플리케이션을 구축 중입니다. 애플리케이션은 새 주문에 대한 정보를 처리하기 위해 Amazon API Gateway REST API에 보냅니다. 회사는 주문이 접수된 순서대로 처리되도록 보장하고자 합니다.
이 요구사항을 충족하는 솔루션은 무엇입니까?

A. 애플리케이션이 주문을 받을 때 API Gateway 통합을 사용하여 Amazon Simple Notification Service (Amazon SNS) 주제로 메시지를 게시합니다. 주제에 AWS Lambda 함수를 구독하여 처리를 수행합니다.
B. 애플리케이션이 주문을 받을 때 API Gateway 통합을 사용하여 Amazon Simple Queue Service (Amazon SQS) FIFO 큐로 메시지를 보냅니다. SQS FIFO 큐를 구성하여 처리를 위해 AWS Lambda 함수를 호출합니다.
C. 애플리케이션이 주문을 처리하는 동안 요청을 차단하기 위해 API Gateway 인가자를 사용합니다.
D. 애플리케이션이 주문을 받을 때 API Gateway 통합을 사용하여 Amazon Simple Queue Service (Amazon SQS) 표준 큐로 메시지를 보냅니다. SQS 표준 큐를 구성하여 처리를 위해 AWS Lambda 함수를 호출합니다.

정답: B.

11.
회사는 Amazon EC2 인스턴스에서 실행되는 애플리케이션과 Amazon Aurora 데이터베이스를 사용하고 있습니다. EC2 인스턴스는 로컬 파일에 저장된 사용자 이름과 비밀번호를 사용하여 데이터베이스에 연결합니다. 회사는 자격 증명 관리의 운영 오버헤드를 최소화하고자 합니다.
솔루션 아키텍트는 이 목표를 달성하기 위해 무엇을 해야 합니까?

A. AWS Secrets Manager를 사용합니다. 자동 회전을 활성화합니다.
B. AWS Systems Manager Parameter Store를 사용합니다. 자동 회전을 활성화합니다.
C. AWS Key Management Service (AWS KMS) 암호화 키로 암호화된 객체를 저장하기 위해 Amazon S3 버킷을 생성합니다. 자격 증명 파일을 S3 버킷으로 마이그레이션합니다. 애플리케이션을 S3 버킷으로 가리키도록 합니다.
D. 각 EC2 인스턴스에 대해 암호화된 Amazon Elastic Block Store (Amazon EBS) 볼륨을 생성합니다. 새 EBS 볼륨을 각 EC2 인스턴스에 연결합니다. 자격 증명 파일을 새 EBS 볼륨으로 마이그레이션합니다. 애플리케이션을 새 EBS 볼륨으로 가리키도록 합니다.

정답: A.

12.
회사는 Amazon EC2 인스턴스 뒤에 Application Load Balancer (ALB)를 사용하여 웹 애플리케이션을 호스팅하고 있습니다. 웹 애플리케이션에는 정적 데이터와 동적 데이터가 있습니다. 회사는 정적 데이터와 동적 데이터의 성능을 향상시키고 지연 시간을 줄이기를 원합니다. 회사는 Amazon Route 53에 등록된 자체 도메인 이름을 사용하고 있습니다.
이 요구사항을 충족하기 위해 솔루션 아키텍트는 무엇을 해야 합니까?

A. Amazon S3 버킷과 ALB를 기원으로 하는 Amazon CloudFront 배포를 생성합니다. Route 53을 구성하여 CloudFront 배포로 트래픽을 라우팅합니다.
B. ALB를 기원으로 하는 Amazon CloudFront 배포를 생성합니다. S3 버킷을 엔드포인트로 하는 AWS Global Accelerator 표준 가속기를 생성합니다. Route 53을 구성하여 CloudFront 배포로 트래픽을 라우팅합니다.
C. S3 버킷을 기원으로 하는 Amazon CloudFront 배포를 생성합니다. ALB와 CloudFront 배포를 엔드포인트로 하는 AWS Global Accelerator 표준 가속기를 생성합니다. 가속기 DNS 이름을 가리키는 사용자 지정 도메인 이름을 생성합니다. 사용자 지정 도메인 이름을 웹 애플리케이션의 엔드포인트로 사용합니다.
D. ALB를 기원으로 하는 Amazon CloudFront 배포를 생성합니다. S3 버킷을 엔드포인트로 하는 AWS Global Accelerator 표준 가속기를 생성합니다. 두 개의 도메인 이름을 생성합니다. 하나의 도메인 이름을 동적 콘텐츠를 위한 CloudFront DNS 이름으로 가리킵니다. 다른 도메인 이름을 정적 콘텐츠를 위한 가속기 DNS 이름으로 가리킵니다. 도메인 이름을 웹 애플리케이션의 엔드포인트로 사용합니다.

정답: A.

13.
회사는 AWS 인프라의 월간 유지보수를 수행합니다. 이 유지보수 활동 중에 여러 AWS 리전에 걸쳐 있는 Amazon RDS for MySQL 데이터베이스의 자격 증명을 주기적으로 교환해야 합니다. 최소한의 운영 오버헤드로 이러한 요구사항을 충족할 수 있는 솔루션은 무엇입니까?

A. 자격 증명을 AWS Secrets Manager에 비밀로 저장합니다. 필요한 리전에 대해 다중 리전 비밀 복제를 사용합니다. Secrets Manager를 구성하여 비밀을 일정에 따라 주기적으로 교환하도록 합니다.
B. 자격 증명을 AWS Systems Manager의 보안 문자열 매개변수로 저장합니다. 필요한 리전에 대해 다중 리전 비밀 복제를 사용합니다. Systems Manager를 구성하여 비밀을 일정에 따라 주기적으로 교환하도록 합니다.
C. 자격 증명을 서버 측 암호화(SSE)가 활성화된 Amazon S3 버킷에 저장합니다. Amazon EventBridge (Amazon CloudWatch Events)를 사용하여 AWS Lambda 함수를 호출하여 자격 증명을 주기적으로 교환합니다.
D. 자격 증명을 AWS Key Management Service (AWS KMS) 다중 리전 고객 관리 키를 사용하여 비밀로 암호화합니다. 비밀을 Amazon DynamoDB 글로벌 테이블에 저장합니다. AWS Lambda 함수를 사용하여 DynamoDB에서 비밀을 검색합니다. RDS API를 사용하여 비밀을 주기적으로 교환합니다.

정답: A.

14.
회사는 Application Load Balancer 뒤에서 Amazon EC2 인스턴스로 전자 상거래 애플리케이션을 실행하고 있습니다. 인스턴스는 여러 가용 영역에 걸쳐 Amazon EC2 Auto Scaling 그룹에서 실행됩니다. Auto Scaling 그룹은 CPU 사용량 메트릭을 기준으로 확장됩니다. 전자 상거래 애플리케이션은 대형 EC2 인스턴스에 호스팅된 MySQL 8.0 데이터베이스에 트랜잭션 데이터를 저장합니다. 애플리케이션 로드가 증가함에 따라 데이터베이스의 성능이 빠르게 저하됩니다. 애플리케이션은 쓰기 트랜잭션보다 읽기 요청을 더 많이 처리합니다. 회사는 예측할 수 없는 읽기 워크로드의 수요를 충족하면서 높은 가용성을 유지하기 위해 자동으로 데이터베이스를 확장할 수 있는 솔루션을 원합니다.
이 요구사항을 충족할 솔루션은 무엇입니까?

A. Amazon Redshift를 리더 및 컴퓨팅 기능을 위한 단일 노드로 사용합니다.
B. 단일 AZ 배포로 Amazon RDS를 사용합니다. Amazon RDS를 구성하여 다른 가용 영역에 리더 인스턴스를 추가합니다.
C. Multi-AZ 배포로 Amazon Aurora를 사용합니다. Aurora Auto Scaling을 Aurora 리플리카로 구성합니다.
D. EC2 스팟 인스턴스를 사용하여 Memcached용 Amazon ElastiCache를 사용합니다.

정답: C.

15.
회사가 최근 AWS로 이전하였으며, 프로덕션 VPC로 들어오고 나가는 트래픽을 보호하는 솔루션을 구현하려고 합니다. 회사는 온프레미스 데이터 센터에서 트래픽 흐름 검사 및 트래픽 필터링과 같은 특정 작업을 수행하는 검사 서버를 운영하였습니다. 회사는 AWS 클라우드에서 동일한 기능을 원합니다.
이 요구사항을 충족할 솔루션은 무엇입니까?

A. Amazon GuardDuty를 사용하여 프로덕션 VPC에서 트래픽 검사 및 트래픽 필터링을 수행합니다.
B. Traffic Mirroring을 사용하여 프로덕션 VPC에서 트래픽을 미러링하여 트래픽 검사 및 필터링을 수행합니다.
C. AWS Network Firewall을 사용하여 프로덕션 VPC에 대한 트래픽 검사 및 트래픽 필터링을 위한 필요한 규칙을 만듭니다.
D. AWS Firewall Manager를 사용하여 프로덕션 VPC에 대한 트래픽 검사 및 트래픽 필터링을 위한 필요한 규칙을 만듭니다.

정답: C.

16.
회사는 AWS에서 데이터 레이크를 호스팅하고 있습니다. 데이터 레이크에는 Amazon S3와 Amazon RDS for PostgreSQL에 있는 데이터가 포함되어 있습니다. 회사는 데이터 시각화를 제공하는 보고 솔루션을 필요로 하며, 이 솔루션은 데이터 레이크 내의 모든 데이터 원본을 포함해야 합니다. 관리팀만 모든 시각화에 완전한 접근 권한을 가질 수 있어야 하며, 회사의 나머지 직원들은 제한된 접근만 가능해야 합니다.
다음 솔루션 중에서 요구사항을 충족하는 것은 무엇입니까?

A. Amazon QuickSight에서 분석을 생성합니다. 모든 데이터 원본에 연결하고 새 데이터셋을 생성하여 데이터를 시각화합니다. 생성된 대시보드를 발행하여 데이터를 시각화하고, 필요한 IAM 역할과 함께 대시보드를 공유합니다.
B. Amazon QuickSight에서 분석을 생성합니다. 모든 데이터 원본에 연결하고 새 데이터셋을 생성하여 데이터를 시각화합니다. 생성된 대시보드를 발행하여 데이터를 시각화하고, 필요한 사용자 및 그룹과 함께 대시보드를 공유합니다.
C. AWS Glue를 사용하여 Amazon S3의 데이터에 대한 테이블과 크롤러를 생성합니다. AWS Glue ETL 작업을 사용하여 보고서를 생성하고, 이를 Amazon S3에 발행합니다. 발행된 보고서에 대한 접근을 제한하기 위해 S3 버킷 정책을 사용합니다.
D. AWS Glue를 사용하여 Amazon S3의 데이터에 대한 테이블과 크롤러를 생성합니다. Amazon Athena Federated Query를 사용하여 Amazon RDS for PostgreSQL 내의 데이터에 접근합니다. Amazon Athena를 사용하여 보고서를 생성하고, 이를 Amazon S3에 발행합니다. 발행된 보고서에 대한 접근을 제한하기 위해 S3 버킷 정책을 사용합니다.

정답: B.

17.
회사가 새로운 비즈니스 애플리케이션을 구현하고 있습니다. 이 애플리케이션은 두 개의 Amazon EC2 인스턴스에서 실행되며 문서 저장을 위해 Amazon S3 버킷을 사용합니다. 솔루션 아키텍트는 EC2 인스턴스가 S3 버킷에 액세스할 수 있도록 보장해야 합니다.
어떻게 해결해야 할까요?

A. S3 버킷에 액세스 권한을 부여하는 IAM 역할을 생성하고, 이 역할을 EC2 인스턴스에 부여합니다.
B. S3 버킷에 액세스 권한을 부여하는 IAM 정책을 생성하고, 이 정책을 EC2 인스턴스에 부여합니다.
C. S3 버킷에 액세스 권한을 부여하는 IAM 그룹을 생성하고, 이 그룹을 EC2 인스턴스에 부여합니다.
D. S3 버킷에 액세스 권한을 부여하는 IAM 사용자를 생성하고, 이 사용자 계정을 EC2 인스턴스에 부여합니다.

정답: A.

18.
사용자가 이미지를 업로드하면 큰 이미지를 작은 압축 이미지로 변환하는 마이크로서비스를 설계 중인 애플리케이션 개발팀이 있습니다. 웹 인터페이스를 통해 이미지를 업로드하면, 마이크로서비스는 해당 이미지를 Amazon S3 버킷에 저장하고, AWS Lambda 함수를 사용하여 이미지를 압축한 다음 압축된 형태의 이미지를 다른 S3 버킷에 저장해야 합니다. 솔루션 설계자는 내구성이 뛰어난 상태 비저장 구성 요소를 사용하여 이미지를 자동으로 처리하는 솔루션을 설계해야 합니다.
다음 조합 중 어떤 것이 요구 사항을 충족시킬까요? (두 가지 선택)

A. Amazon Simple Queue Service (Amazon SQS) 큐를 생성합니다. 이미지가 S3 버킷에 업로드되면 SQS 큐로 알림을 보내도록 S3 버킷을 구성합니다.
B. Lambda 함수를 구성하여 Amazon Simple Queue Service (Amazon SQS) 큐를 호출 소스로 사용합니다. SQS 메시지가 성공적으로 처리되면 큐에서 메시지를 삭제합니다.
C. Lambda 함수를 구성하여 S3 버킷을 모니터링하도록 설정합니다. 업로드된 이미지가 감지되면 메모리에 있는 텍스트 파일에 파일 이름을 기록하고 처리된 이미지를 추적하는 데 사용합니다.
D. Amazon Simple Queue Service (Amazon SQS) 큐를 모니터링할 Amazon EC2 인스턴스를 시작합니다. 큐에 항목이 추가되면 EC2 인스턴스의 텍스트 파일에 파일 이름을 로깅하고 Lambda 함수를 호출합니다.
E. Amazon EventBridge (Amazon CloudWatch Events) 이벤트를 구성하여 S3 버킷을 모니터링합니다. 이미지가 업로드되면 애플리케이션 소유자의 이메일 주소로 추가 처리를 위한 Amazon Simple Notification Service (Amazon SNS) 토픽에 경고를 전송합니다.

정답(a,b)

19.
회사는 AWS에서 세 개의 티어 웹 애플리케이션을 운영하고 있습니다. 웹 서버는 VPC의 퍼블릭 서브넷에 배포되어 있고, 애플리케이션 서버와 데이터베이스 서버는 같은 VPC의 프라이빗 서브넷에 배포되어 있습니다. 회사는 AWS Marketplace에서 제공하는 제3자 가상 방화벽 애플라이언스를 인스펙션 VPC에 배포했습니다. 이 애플라이언스는 IP 패킷을 수신할 수 있는 IP 인터페이스로 구성되어 있습니다. 솔루션 아키텍트는 웹 애플리케이션을 이 애플라이언스와 통합하여 모든 트래픽을 웹 서버에 도달하기 전에 검사할 필요가 있습니다.
어떤 해결책이 최소의 운영 오버헤드로 이 요구사항을 충족시킬까요?

A. 웹 어플리케이션의 VPC의 퍼블릭 서브넷에 네트워크 로드 밸런서를 생성하여 트래픽을 애플라이언스로 라우팅합니다.
B. 웹 어플리케이션의 VPC의 퍼블릭 서브넷에 애플리케이션 로드 밸런서를 생성하여 트래픽을 애플라이언스로 라우팅합니다.
C. 인스펙션 VPC에 트랜지트 게이트웨이를 배포하고, 수신된 패킷을 트랜지트 게이트웨이로 보냅니다.
D. 인스펙션 VPC에 게이트웨이 로드 밸런서를 배포하고, 이 로드 밸런서 엔드포인트로 수신된 패킷을 전송합니다.

정답: B

20.
한 회사가 AWS 리전 내에서 프로덕션 데이터를 테스트 환경으로 대량 복제하는 능력을 향상시키려고 합니다. 이 데이터는 Amazon EC2 인스턴스의 Amazon Elastic Block Store (Amazon EBS) 볼륨에 저장되어 있습니다. 복제된 데이터의 수정 사항은 프로덕션 환경에 영향을 미치지 않아야 합니다. 이 데이터에 접근하는 소프트웨어는 일관되게 높은 I/O 성능을 요구합니다.
솔루션 아키텍트는 프로덕션 데이터를 테스트 환경으로 복제하는 데 필요한 시간을 최소화해야 합니다.
이 요구 사항을 충족하는 솔루션은 무엇입니까?

A. 프로덕션 EBS 볼륨의 EBS 스냅샷을 찍습니다. 이 스냅샷을 테스트 환경의 EC2 인스턴스 스토어 볼륨에 복원합니다.
B. 프로덕션 EBS 볼륨을 EBS Multi-Attach 기능으로 구성합니다. 프로덕션 EBS 볼륨의 EBS 스냅샷을 찍습니다. 이 스냅샷을 테스트 환경의 EC2 인스턴스에 연결합니다.
C. 프로덕션 EBS 볼륨의 EBS 스냅샷을 찍습니다. 새로운 EBS 볼륨을 생성하고 초기화합니다. 이 새로운 볼륨을 테스트 환경의 EC2 인스턴스에 연결한 후 프로덕션 EBS 스냅샷에서 볼륨을 복원합니다.
D. 프로덕션 EBS 볼륨의 EBS 스냅샷을 찍습니다. EBS 빠른 스냅샷 복원 기능을 활성화합니다. 이 스냅샷을 새로운 EBS 볼륨에 복원한 후 이 볼륨을 테스트 환경의 EC2 인스턴스에 연결합니다.

정답: D. 

21.
한 전자상거래 회사가 AWS에서 매일 하나의 특가 상품을 소개하는 웹사이트를 론칭하려고 합니다. 매일 24시간 동안 정확히 하나의 상품이 할인 판매될 예정입니다. 회사는 매 시간 수백만 건의 요청을 처리하고, 피크 시간에는 밀리초 단위의 지연 시간을 제공할 수 있어야 합니다. 이 요구 사항을 가장 적은 운영 오버헤드로 충족할 수 있는 솔루션은 무엇입니까?

A. Amazon S3를 사용하여 웹사이트 전체를 다른 S3 버킷에 호스팅합니다. Amazon CloudFront 배포를 추가하고, S3 버킷을 배포의 오리진으로 설정합니다. 주문 데이터는 Amazon S3에 저장합니다.
B. 여러 가용 영역에 걸쳐 Amazon EC2 인스턴스에 전체 웹사이트를 배포합니다. Auto Scaling 그룹을 사용하여 인스턴스를 자동으로 확장합니다. 웹사이트 트래픽을 분산하기 위해 Application Load Balancer (ALB)를 추가합니다. 백엔드 API를 위한 또 다른 ALB를 추가합니다. 데이터는 Amazon RDS for MySQL에 저장합니다.
C. 전체 애플리케이션을 컨테이너로 마이그레이션합니다. Amazon Elastic Kubernetes Service (Amazon EKS)에서 컨테이너를 호스팅합니다. Kubernetes Cluster Autoscaler를 사용하여 트래픽 버스트를 처리할 포드의 수를 자동으로 조정합니다. 데이터는 Amazon RDS for MySQL에 저장합니다.
D. Amazon S3 버킷을 사용하여 웹사이트의 정적 콘텐츠를 호스팅합니다. Amazon CloudFront 배포를 배포합니다. S3 버킷을 오리진으로 설정합니다. 백엔드 API에는 Amazon API Gateway와 AWS Lambda 함수를 사용합니다. 데이터는 Amazon DynamoDB에 저장합니다.

정답: D.

22.
한 솔루션 설계자가 Amazon S3를 사용하여 새로운 디지털 미디어 애플리케이션의 스토리지 아키텍처를 설계하고 있습니다. 미디어 파일은 가용성 영역의 손실에 탄력적이어야 합니다. 일부 파일은 자주 액세스되지만 다른 파일은 예측할 수 없는 패턴으로 액세스되는 경우가 거의 없습니다. 솔루션 설계자는 미디어 파일을 저장하고 검색하는 비용을 최소화해야 합니다.
이러한 요구 사항을 충족하는 스토리지 옵션은 무엇입니까?

A. S3 Standard
B. S3 Intelligent-Tiering
C. S3 Standard-Infrequent Access (S3 Standard-IA)
D. S3 One Zone-Infrequent Access (S3 One Zone-IA)
 
정답: B

23.
회사는 Amazon S3 Standard 저장소를 사용하여 백업 파일을 저장하고 있습니다. 이 파일들은 한 달 동안 자주 접근되지만, 한 달이 지나면 접근되지 않습니다. 회사는 파일을 무기한 보관해야 합니다. 가장 비용 효율적인 저장 솔루션은 무엇입니까?

A. S3 Intelligent-Tiering을 구성하여 객체를 자동으로 마이그레이션합니다.
B. S3 Standard에서 S3 Glacier Deep Archive로 객체를 한 달 후에 전환하도록 S3 수명 주기 구성을 만듭니다.
C. S3 Standard에서 S3 Standard-Infrequent Access (S3 Standard-IA)로 객체를 한 달 후에 전환하도록 S3 수명 주기 구성을 만듭니다.
D. S3 Standard에서 S3 One Zone-Infrequent Access (S3 One Zone-IA)로 객체를 한 달 후에 전환하도록 S3 수명 주기 구성을 만듭니다.

정답은 B

24.
회사는 최근 청구서에서 Amazon EC2 비용이 증가한 것을 관찰했습니다. 청구팀은 몇 개의 EC2 인스턴스에 대해 원하지 않는 수직적 확장이 있었음을 발견했습니다. 솔루션 아키텍트는 지난 2개월 간의 EC2 비용을 비교하는 그래프를 생성하고, 수직적 확장의 근본 원인을 식별하기 위한 심층 분석을 수행해야 합니다. 솔루션 아키텍트는 최소한의 운영 오버헤드로 정보를 생성해야 합니다.
어떻게 솔루션 아키텍트가 정보를 생성할 수 있습니까?

A. AWS Budgets를 사용하여 예산 보고서를 작성하고 인스턴스 유형을 기준으로 EC2 비용을 비교합니다.
B. Cost Explorer의 세밀한 필터링 기능을 사용하여 인스턴스 유형을 기준으로 EC2 비용의 심층 분석을 수행합니다.
C. AWS Billing and Cost Management 대시보드의 그래프를 사용하여 지난 2개월 동안 인스턴스 유형을 기준으로 EC2 비용을 비교합니다.
D. AWS Cost and Usage Reports를 사용하여 보고서를 생성하고 Amazon S3 버킷으로 전송합니다. Amazon S3를 소스로 사용하는 Amazon QuickSight를 사용하여 인스턴스 유형을 기준으로 대화형 그래프를 생성합니다.

정답은 **B

25.
회사가 애플리케이션을 설계하고 있습니다. 이 애플리케이션은 AWS Lambda 함수를 사용하여 Amazon API Gateway를 통해 정보를 받고, 이 정보를 Amazon Aurora PostgreSQL 데이터베이스에 저장합니다. 개념 증명 단계에서, 회사는 데이터베이스에 로드해야 하는 높은 데이터 볼륨을 처리하기 위해 Lambda 할당량을 크게 늘려야 합니다. 솔루션 아키텍트는 확장성을 개선하고 구성 노력을 최소화하는 새로운 설계를 추천해야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족합니까?

A. Lambda 함수 코드를 Apache Tomcat 코드로 리팩토링하여 Amazon EC2 인스턴스에서 실행합니다. 네이티브 Java Database Connectivity (JDBC) 드라이버를 사용하여 데이터베이스에 연결합니다.
B. 플랫폼을 Aurora에서 Amazon DynamoDB로 변경합니다. DynamoDB Accelerator (DAX) 클러스터를 프로비저닝합니다. DAX 클라이언트 SDK를 사용하여 기존 DynamoDB API 호출을 DAX 클러스터에 포인팅합니다.
C. 두 개의 Lambda 함수를 설정합니다. 하나의 함수는 정보를 수신하도록 구성하고, 다른 함수는 정보를 데이터베이스에 로드하도록 구성합니다. Amazon Simple Notification Service (Amazon SNS)를 사용하여 Lambda 함수들을 통합합니다.
D. 두 개의 Lambda 함수를 설정합니다. 하나의 함수는 정보를 수신하도록 구성하고, 다른 함수는 정보를 데이터베이스에 로드하도록 구성합니다. Amazon Simple Queue Service (Amazon SQS) 큐를 사용하여 Lambda 함수들을 통합합니다.

정답은 D.

26.

회사가 Amazon S3 버킷에 대해 무단 구성 변경이 없는지 확인하기 위해 AWS Cloud 배포를 검토해야 합니다. 솔루션 아키텍트는 이를 달성하기 위해 무엇을 해야 합니까?

A. 적절한 규칙과 함께 AWS Config를 켭니다.
B. 적절한 검사를 통해 AWS Trusted Advisor를 켭니다.
C. 적절한 평가 템플릿으로 Amazon Inspector를 켭니다.
D. Amazon S3 서버 액세스 로깅을 켭니다. Amazon EventBridge(Amazon CloudWatch Events)를 구성합니다.

정답은 **A

27.
회사가 새 애플리케이션을 출시하고 있으며, 애플리케이션 메트릭을 Amazon CloudWatch 대시보드에 표시할 예정입니다. 회사의 제품 관리자는 주기적으로 이 대시보드에 액세스할 필요가 있지만 AWS 계정이 없습니다. 솔루션 아키텍트는 최소 권한 원칙을 준수하면서 제품 관리자에게 액세스를 제공해야 합니다.
이 요구 사항을 충족하는 솔루션은 무엇입니까?

A. CloudWatch 콘솔에서 대시보드를 공유합니다. 제품 관리자의 이메일 주소를 입력하고 공유 단계를 완료합니다. 대시보드에 대한 공유 가능한 링크를 제품 관리자에게 제공합니다.
B. 제품 관리자용으로 특정 IAM 사용자를 생성합니다. 이 사용자에게 CloudWatchReadOnlyAccess AWS 관리형 정책을 연결합니다. 새로운 로그인 자격 증명을 제품 관리자와 공유합니다. 올바른 대시보드의 브라우저 URL을 제품 관리자와 공유합니다.
C. 회사 직원용으로 IAM 사용자를 생성합니다. 이 사용자에게 ViewOnlyAccess AWS 관리형 정책을 연결합니다. 새로운 로그인 자격 증명을 제품 관리자와 공유합니다. 제품 관리자에게 CloudWatch 콘솔로 이동하여 대시보드 섹션에서 이름으로 대시보드를 찾도록 요청합니다.
D. 공용 서브넷에 배스천 서버를 배포합니다. 제품 관리자가 대시보드에 액세스해야 할 때 서버를 시작하고 RDP 자격 증명을 공유합니다. 배스천 서버에서 브라우저가 적절한 권한을 가진 캐시된 AWS 자격 증명으로 대시보드 URL을 열도록 구성합니다.

정답: A

28.
회사가 애플리케이션을 AWS로 마이그레이션하고 있습니다. 애플리케이션은 다른 계정에 배포되어 있으며, 회사는 AWS Organizations를 사용하여 계정을 중앙에서 관리하고 있습니다. 회사의 보안 팀은 모든 회사 계정에 대해 단일 사인온(SSO) 솔루션이 필요합니다. 회사는 온프레미스 자가 관리 Microsoft Active Directory에서 사용자와 그룹을 계속 관리해야 합니다.
이 요구 사항을 충족하는 솔루션은 무엇입니까?

A. AWS SSO 콘솔에서 AWS Single Sign-On (AWS SSO)을 활성화합니다. AWS Directory Service for Microsoft Active Directory를 사용하여 회사의 자가 관리 Microsoft Active Directory와 AWS SSO를 연결하기 위해 일방향 포리스트 트러스트 또는 일방향 도메인 트러스트를 생성합니다.
B. AWS SSO 콘솔에서 AWS Single Sign-On (AWS SSO)을 활성화합니다. AWS Directory Service for Microsoft Active Directory를 사용하여 회사의 자가 관리 Microsoft Active Directory와 AWS SSO를 연결하기 위해 양방향 포리스트 트러스트를 생성합니다.
C. AWS Directory Service를 사용합니다. 회사의 자가 관리 Microsoft Active Directory와 양방향 트러스트 관계를 생성합니다.
D. 온프레미스에 IdP(Identity Provider)를 배포합니다. AWS SSO 콘솔에서 AWS Single Sign-On (AWS SSO)을 활성화합니다.

정답: A.

29.
회사는 UDP 연결을 사용하는 VoIP(Voice over Internet Protocol) 서비스를 제공합니다. 이 서비스는 Auto Scaling 그룹에서 실행되는 Amazon EC2 인스턴스로 구성되어 있으며, 여러 AWS 리전에 배포되어 있습니다. 회사는 사용자에게 가장 낮은 대기 시간을 제공하는 리전으로 라우팅하고, 리전 간 자동 장애 조치를 필요로 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

A. Network Load Balancer (NLB)와 관련된 대상 그룹을 배포합니다. 대상 그룹을 Auto Scaling 그룹과 연관시킵니다. 각 리전에서 NLB를 AWS Global Accelerator 엔드포인트로 사용합니다.
B. Application Load Balancer (ALB)와 관련된 대상 그룹을 배포합니다. 대상 그룹을 Auto Scaling 그룹과 연관시킵니다. 각 리전에서 ALB를 AWS Global Accelerator 엔드포인트로 사용합니다.
C. Network Load Balancer (NLB)와 관련된 대상 그룹을 배포합니다. 대상 그룹을 Auto Scaling 그룹과 연관시킵니다. 각 NLB에 대한 별칭을 가리키는 Amazon Route 53 지연 시간 레코드를 생성합니다. 지연 시간 레코드를 원본으로 사용하는 Amazon CloudFront 배포를 생성합니다.
D. Application Load Balancer (ALB)와 관련된 대상 그룹을 배포합니다. 대상 그룹을 Auto Scaling 그룹과 연관시킵니다. 각 ALB에 대한 별칭을 가리키는 Amazon Route 53 가중치 레코드를 생성합니다. 가중치 레코드를 원본으로 사용하는 Amazon CloudFront 배포를 생성합니다.

정답은 A


30.
개발 팀은 월별로 자원 집약적인 테스트를 수행하고 있습니다. 이 테스트는 성능 인사이트가 활성화된 일반용 Amazon RDS for MySQL DB 인스턴스에서 진행됩니다. 테스트는 매월 48시간 동안 진행되며 데이터베이스를 사용하는 유일한 프로세스입니다. 팀은 테스트 실행 비용을 줄이고 DB 인스턴스의 컴퓨팅 및 메모리 속성을 유지하고자 합니다.

가장 비용 효율적으로 이 요구 사항을 충족하는 솔루션은 무엇입니까?

A. 테스트가 완료되면 DB 인스턴스를 중지합니다. 필요할 때 DB 인스턴스를 다시 시작합니다.
B. DB 인스턴스에 Auto Scaling 정책을 사용하여 테스트가 완료되면 자동으로 스케일을 조정합니다.
C. 테스트가 완료되면 스냅샷을 생성합니다. DB 인스턴스를 종료하고 필요할 때 스냅샷을 복원합니다.
D. 테스트가 완료되면 DB 인스턴스를 저용량 인스턴스로 수정합니다. 다시 필요할 때 DB 인스턴스를 수정합니다.

정답: A

31.
AWS에 호스팅된 웹 애플리케이션을 운영하는 회사는 모든 Amazon EC2 인스턴스, Amazon RDS DB 인스턴스 및 Amazon Redshift 클러스터가 태그로 구성되어 있는지 확인하고자 합니다. 회사는 이 확인 작업의 설정과 운영 노력을 최소화하려고 합니다. 솔루션 아키텍트는 어떻게 해야 할까요?

A. AWS Config 규칙을 사용하여 올바르게 태그가 지정되지 않은 리소스를 정의하고 감지합니다.
B. 비용 탐색기를 사용하여 올바르게 태그가 지정되지 않은 리소스를 표시합니다. 이러한 리소스에 태그를 수동으로 추가합니다.
C. 모든 리소스에 대해 올바른 태그 할당을 확인하기 위해 API 호출을 작성합니다. EC2 인스턴스에서 주기적으로 코드를 실행합니다.
D. 모든 리소스에 대해 올바른 태그 할당을 확인하기 위해 API 호출을 작성합니다. Amazon CloudWatch를 통해 주기적으로 코드를 실행할 AWS Lambda 함수를 스케줄링합니다.

정답: A

32.
개발 팀은 다른 팀에서 접근할 수 있는 웹사이트를 호스팅해야 합니다. 웹사이트는 HTML, CSS, 클라이언트 측 JavaScript 및 이미지로 구성되어 있습니다. 가장 비용 효율적인 웹사이트 호스팅 방법은 무엇입니까?

A. 웹사이트를 컨테이너화하고 AWS Fargate에서 호스팅합니다.
B. Amazon S3 버킷을 생성하고 웹사이트를 거기에 호스팅합니다.
C. Amazon EC2 인스턴스에 웹 서버를 배포하여 호스팅합니다.
D. Express.js 프레임워크를 사용하는 AWS Lambda 타겟을 설정한 Application Load Balancer를 구성합니다.

정답: B. 

33.
한 회사가 AWS에서 온라인 마켓플레이스 웹 애플리케이션을 운영하고 있습니다. 이 애플리케이션은 최대 시간대에 수십만 명의 사용자를 서비스합니다. 회사는 수백만 건의 금융 거래 세부 정보를 여러 내부 애플리케이션과 공유해야 하는 확장 가능하고 거의 실시간 솔루션이 필요합니다. 거래는 또한 민감한 데이터를 제거하여 저지연 시간으로 문서 데이터베이스에 저장되어야 합니다.
솔루션 아키텍트는 이러한 요구 사항을 충족하기 위해 무엇을 권장해야 합니까?

A. Amazon DynamoDB에 거래 데이터를 저장합니다. DynamoDB 규칙을 설정하여 모든 거래가 기록될 때 민감한 데이터를 제거합니다. DynamoDB Streams를 사용하여 다른 애플리케이션과 거래 데이터를 공유합니다.
B. 거래 데이터를 Amazon Kinesis Data Firehose로 스트리밍하여 Amazon DynamoDB 및 Amazon S3에 데이터를 저장합니다. Kinesis Data Firehose와 AWS Lambda 통합을 사용하여 민감한 데이터를 제거합니다. 다른 애플리케이션은 Amazon S3에 저장된 데이터를 소비할 수 있습니다.
C. 거래 데이터를 Amazon Kinesis Data Streams로 스트리밍합니다. AWS Lambda 통합을 사용하여 각 거래에서 민감한 데이터를 제거한 후 Amazon DynamoDB에 데이터를 저장합니다. 다른 애플리케이션은 Kinesis 데이터 스트림에서 거래 데이터를 소비할 수 있습니다.
D. 배치 처리된 거래 데이터를 파일로 Amazon S3에 저장합니다. AWS Lambda를 사용하여 각 파일에서 민감한 데이터를 처리한 후 Amazon S3에 업데이트된 데이터를 저장합니다. Lambda 함수는 데이터를 Amazon DynamoDB에 저장합니다. 다른 애플리케이션은 Amazon S3에 저장된 거래 파일을 소비할 수 있습니다.

정답: c.

34.
한 회사가 AWS에 멀티 티어 애플리케이션을 호스팅하고 있습니다. 규정 준수, 거버넌스, 감사 및 보안을 위해 회사는 AWS 리소스에 대한 구성 변경 사항을 추적하고 이러한 리소스에 대한 API 호출 기록을 저장해야 합니다. 솔루션 아키텍트는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?

A. 구성 변경 사항을 추적하기 위해 AWS CloudTrail을 사용하고, API 호출을 기록하기 위해 AWS Config를 사용합니다.
B. 구성 변경 사항을 추적하기 위해 AWS Config를 사용하고, API 호출을 기록하기 위해 AWS CloudTrail을 사용합니다.
C. 구성 변경 사항을 추적하기 위해 AWS Config를 사용하고, API 호출을 기록하기 위해 Amazon CloudWatch를 사용합니다.
D. 구성 변경 사항을 추적하기 위해 AWS CloudTrail을 사용하고, API 호출을 기록하기 위해 Amazon CloudWatch를 사용합니다.

정답: B. 

35.
한 회사가 AWS 클라우드에서 공개적으로 접근할 수 있는 웹 애플리케이션을 출시할 준비를 하고 있습니다. 아키텍처는 Elastic Load Balancer (ELB) 뒤의 VPC 내 Amazon EC2 인스턴스로 구성되어 있습니다. DNS는 서드파티 서비스를 사용하고 있습니다. 회사의 솔루션 아키텍트는 대규모 DDoS 공격을 탐지하고 방어하기 위한 솔루션을 추천해야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

A. 계정에서 Amazon GuardDuty를 활성화합니다.
B. EC2 인스턴스에서 Amazon Inspector를 활성화합니다.
C. AWS Shield를 활성화하고 Amazon Route 53에 할당합니다.
D. AWS Shield Advanced를 활성화하고 ELB에 할당합니다.

정답: D.

36.
한 회사가 AWS 클라우드에서 애플리케이션을 구축하고 있습니다. 애플리케이션은 두 개의 AWS 리전 내의 Amazon S3 버킷에 데이터를 저장할 예정입니다. 회사는 AWS Key Management Service (AWS KMS) 고객 관리 키를 사용하여 S3 버킷에 저장된 모든 데이터를 암호화해야 합니다. 두 S3 버킷의 데이터는 동일한 KMS 키로 암호화되고 복호화되어야 합니다. 데이터와 키는 두 리전 각각에 저장되어야 합니다. 최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

A. 각 리전에 S3 버킷을 생성합니다. S3 버킷을 Amazon S3 관리 암호화 키(SSE-S3)를 사용하도록 구성합니다. S3 버킷 간의 복제를 구성합니다.
B. 고객 관리 멀티 리전 KMS 키를 생성합니다. 각 리전에 S3 버킷을 생성합니다. S3 버킷 간의 복제를 구성합니다. 애플리케이션이 클라이언트 측 암호화를 사용하여 KMS 키를 사용하도록 구성합니다.
C. 각 리전에 고객 관리 KMS 키와 S3 버킷을 생성합니다. S3 버킷을 Amazon S3 관리 암호화 키(SSE-S3)를 사용하도록 구성합니다. S3 버킷 간의 복제를 구성합니다.
D. 각 리전에 고객 관리 KMS 키와 S3 버킷을 생성합니다. S3 버킷을 AWS KMS 키(SSE-KMS)를 사용하도록 구성합니다. S3 버킷 간의 복제를 구성합니다.

정답: B.

37.
한 회사가 최근 AWS 계정에서 Amazon EC2 인스턴스에 다양한 새로운 워크로드를 출시했습니다. 회사는 인스턴스에 원격으로 안전하게 접근하고 관리할 수 있는 전략을 수립해야 합니다. 회사는 AWS 네이티브 서비스를 사용하고 AWS Well-Architected Framework를 따르는 반복 가능한 프로세스를 구현해야 합니다. 최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

A. EC2 시리얼 콘솔을 사용하여 각 인스턴스의 터미널 인터페이스에 직접 접근하여 관리합니다.
B. 각 기존 인스턴스와 새 인스턴스에 적절한 IAM 역할을 할당합니다. AWS Systems Manager Session Manager를 사용하여 원격 SSH 세션을 설정합니다.
C. 관리용 SSH 키 페어를 생성합니다. 각 EC2 인스턴스에 공개 키를 로드합니다. 각 인스턴스를 관리하기 위한 터널을 제공하기 위해 퍼블릭 서브넷에 배스천 호스트를 배포합니다.
D. AWS Site-to-Site VPN 연결을 설정합니다. 관리자가 로컬 온프레미스 머신을 사용하여 VPN 터널을 통해 SSH 키를 사용하여 인스턴스에 직접 연결하도록 지시합니다.

정답: B

38.
한 회사가 Amazon S3에서 정적 웹사이트를 호스팅하고 있으며, Amazon Route 53을 DNS로 사용하고 있습니다. 웹사이트는 전 세계적으로 증가하는 수요를 경험하고 있습니다. 회사는 웹사이트에 접근하는 사용자들의 지연 시간을 줄여야 합니다. 가장 비용 효율적으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

A. 웹사이트를 포함한 S3 버킷을 모든 AWS 리전으로 복제합니다. Route 53 지리적 위치 라우팅 항목을 추가합니다.
B. AWS Global Accelerator에서 가속기를 프로비저닝합니다. 제공된 IP 주소를 S3 버킷과 연결합니다. Route 53 항목을 편집하여 가속기의 IP 주소를 가리키도록 합니다.
C. S3 버킷 앞에 Amazon CloudFront 배포를 추가합니다. Route 53 항목을 편집하여 CloudFront 배포를 가리키도록 합니다.
D. S3 Transfer Acceleration을 버킷에서 활성화합니다. Route 53 항목을 편집하여 새로운 엔드포인트를 가리키도록 합니다.

정답: C.

39.
한 회사는 웹사이트에 검색 가능한 항목 저장소를 유지하고 있습니다. 데이터는 1,000만 개 이상의 행을 포함한 Amazon RDS for MySQL 데이터베이스 테이블에 저장되어 있습니다. 데이터베이스는 2TB의 범용 SSD 스토리지를 사용합니다. 회사의 웹사이트를 통해 매일 수백만 건의 데이터 업데이트가 이루어지고 있습니다.
회사는 일부 삽입 작업이 10초 이상 걸린다는 것을 발견했습니다. 데이터베이스 스토리지 성능이 문제임을 확인했습니다.
이 성능 문제를 해결하는 솔루션은 무엇입니까?

A. 스토리지 유형을 프로비저닝된 IOPS SSD로 변경합니다.
B. DB 인스턴스를 메모리 최적화 인스턴스 클래스으로 변경합니다.
C. DB 인스턴스를 버스트 성능 인스턴스 클래스으로 변경합니다.
D. MySQL 네이티브 비동기 복제를 사용하여 Multi-AZ RDS 읽기 복제를 활성화합니다.

정답: A

40.
한 회사는 수천 개의 엣지 디바이스를 보유하고 있으며, 이 디바이스들은 매일 총 1TB의 상태 알림을 생성합니다. 각 알림의 크기는 약 2KB입니다. 솔루션 아키텍트는 이러한 알림을 수집하고 저장하여 나중에 분석할 수 있는 솔루션을 구현해야 합니다. 회사는 고가용성 솔루션을 원하지만, 비용을 최소화하고 추가 인프라를 관리하지 않기를 원합니다. 또한, 회사는 14일간의 데이터를 즉시 분석할 수 있도록 유지하고, 14일이 지난 데이터는 아카이브하려고 합니다. 이러한 요구 사항을 가장 운영 효율적으로 충족하는 솔루션은 무엇입니까?

A. 알림을 수집하기 위해 Amazon Kinesis Data Firehose 전달 스트림을 생성합니다. Kinesis Data Firehose 스트림을 구성하여 알림을 Amazon S3 버킷으로 전달합니다. 14일 후 데이터를 Amazon S3 Glacier로 전환하는 S3 수명주기 구성을 설정합니다.
B. 두 개의 가용 영역에 Amazon EC2 인스턴스를 시작하고, Elastic Load Balancer 뒤에 배치하여 알림을 수집합니다. EC2 인스턴스에서 스크립트를 작성하여 알림을 Amazon S3 버킷에 저장합니다. 14일 후 데이터를 Amazon S3 Glacier로 전환하는 S3 수명주기 구성을 설정합니다.
C. 알림을 수집하기 위해 Amazon Kinesis Data Firehose 전달 스트림을 생성합니다. Kinesis Data Firehose 스트림을 구성하여 알림을 Amazon OpenSearch Service (Amazon Elasticsearch Service) 클러스터로 전달합니다. Amazon OpenSearch Service (Amazon Elasticsearch Service) 클러스터를 설정하여 매일 수동 스냅샷을 찍고, 14일 이상된 데이터를 클러스터에서 삭제합니다.
D. 알림을 수집하기 위해 Amazon Simple Queue Service (Amazon SQS) 표준 대기열을 생성하고, 메시지 보존 기간을 14일로 설정합니다. 소비자가 SQS 대기열을 폴링하여 메시지의 나이를 확인하고 필요한 경우 메시지 데이터를 분석하도록 구성합니다. 메시지가 14일이 되면, 소비자가 메시지를 Amazon S3 버킷에 복사하고 SQS 대기열에서 메시지를 삭제해야 합니다.

정답: A.

