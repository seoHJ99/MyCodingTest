1.
회사는 여러 대륙의 도시에서 온도, 습도 및 기압 데이터를 수집하고 있습니다. 각 사이트에서 일일 평균 500GB의 데이터를 수집합니다. 각 사이트는 고속 인터넷 연결을 보유하고 있습니다.
회사는 이러한 전 세계 사이트의 데이터를 가능한 한 빨리 단일 Amazon S3 버킷으로 집계하고자 합니다. 솔루션은 운영 복잡성을 최소화해야 합니다.
이 요구사항을 충족하는 솔루션은 무엇입니까?

A. 대상 S3 버킷에서 S3 Transfer Acceleration을 활성화합니다. 멀티파트 업로드를 사용하여 사이트 데이터를 대상 S3 버킷으로 직접 업로드합니다.
B. 각 사이트에서 가장 가까운 리전의 S3 버킷으로 데이터를 업로드합니다. S3 Cross-Region Replication을 사용하여 객체를 대상 S3 버킷으로 복사합니다. 그런 다음 원본 S3 버킷에서 데이터를 제거합니다.
C. 매일 AWS Snowball Edge Storage Optimized 디바이스 작업을 예약하여 각 사이트에서 가장 가까운 리전으로 데이터를 전송합니다. S3 Cross-Region Replication을 사용하여 객체를 대상 S3 버킷으로 복사합니다.
D. 각 사이트에서 가장 가까운 리전의 Amazon EC2 인스턴스로 데이터를 업로드합니다. 데이터를 Amazon Elastic Block Store (Amazon EBS) 볼륨에 저장합니다. 정기적으로 EBS 스냅샷을 찍어 대상 S3 버킷이 있는 리전으로 복사합니다. 해당 리전에서 EBS 볼륨을 복원합니다.
(a)

2.
회사는 독점 애플리케이션의 로그 파일을 분석할 수 있어야 합니다. 로그는 JSON 형식으로 Amazon S3 버킷에 저장되어 있습니다. 쿼리는 간단하며 필요할 때 실행됩니다. 솔루션 아키텍트는 최소한의 아키텍처 변경으로 분석을 수행해야 합니다.
운영 오버헤드를 최소화하면서 이러한 요구 사항을 충족하기 위해 솔루션 아키텍트는 무엇을 해야 합니까?

A. Amazon Redshift를 사용하여 모든 내용을 한 곳에 로드하고 필요한 SQL 쿼리를 실행합니다.
B. Amazon CloudWatch Logs를 사용하여 로그를 저장합니다. Amazon CloudWatch 콘솔에서 필요한 SQL 쿼리를 실행합니다.
C. Amazon Athena를 직접 Amazon S3와 함께 사용하여 필요한 쿼리를 실행합니다.
D. AWS Glue를 사용하여 로그를 카탈로그화합니다. Amazon EMR에서 일시적인 Apache Spark 클러스터를 사용하여 필요한 SQL 쿼리를 실행합니다.
(c)

3.
회사는 여러 부서의 다양한 AWS 계정을 관리하기 위해 AWS Organizations를 사용합니다. 관리 계정에는 프로젝트 보고서를 포함하는 Amazon S3 버킷이 있습니다. 회사는 이 S3 버킷에 대한 접근을 AWS Organizations 내의 계정 사용자에게만 제한하고자 합니다.
운영 오버헤드를 최소화하면서 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

A. S3 버킷 정책에 조직 ID를 참조하여 aws PrincipalOrgID 글로벌 조건 키를 추가합니다.
B. 각 부서를 위해 조직 단위(OU)를 생성합니다. S3 버킷 정책에 aws
글로벌 조건 키를 추가합니다.
C. AWS CloudTrail을 사용하여 CreateAccount, InviteAccountToOrganization, LeaveOrganization 및 RemoveAccountFromOrganization 이벤트를 모니터링합니다. S3 버킷 정책을 이에 따라 업데이트합니다.
D. S3 버킷에 접근이 필요한 각 사용자에게 태그를 지정합니다. S3 버킷 정책에 aws
글로벌 조건 키를 추가합니다.
(a)

4.
애플리케이션이 VPC 내의 Amazon EC2 인스턴스에서 실행됩니다. 이 애플리케이션은 Amazon S3 버킷에 저장된 로그를 처리합니다. EC2 인스턴스는 인터넷에 연결되지 않고 S3 버킷에 접근해야 합니다.
Amazon S3에 대한 사설 네트워크 연결을 제공할 솔루션은 무엇입니까?

A. S3 버킷에 대한 게이트웨이 VPC 엔드포인트를 생성합니다.
B. 로그를 Amazon CloudWatch Logs로 스트리밍합니다. 로그를 S3 버킷으로 내보냅니다.
C. Amazon EC2에 S3 접근을 허용하는 인스턴스 프로파일을 생성합니다.
D. S3 엔드포인트에 접근하기 위해 프라이빗 링크가 있는 Amazon API Gateway API를 생성합니다.
(a)

5.
회사는 AWS에서 웹 애플리케이션을 호스팅 중이며, 사용자 업로드 문서를 Amazon EBS 볼륨에 저장하고 있습니다. 더 나은 확장성과 가용성을 위해 아키텍처를 복제하여 다른 가용 영역에 두 번째 EC2 인스턴스와 EBS 볼륨을 생성하고, 두 인스턴스를 Application Load Balancer 뒤에 배치했습니다. 이 변경 후, 사용자가 웹사이트를 새로고침할 때마다 문서의 하위 집합만 보게 되며, 한 번에 모든 문서를 볼 수 없습니다.
사용자가 한 번에 모든 문서를 볼 수 있도록 하기 위해 솔루션 아키텍트가 제안해야 할 해결책은 무엇입니까?

A. 데이터를 복사하여 두 EBS 볼륨이 모든 문서를 포함하도록 합니다.
B. Application Load Balancer를 구성하여 사용자가 문서가 있는 서버로 향하게 합니다.
C. 두 EBS 볼륨의 데이터를 Amazon EFS로 복사합니다. 애플리케이션을 수정하여 새 문서를 Amazon EFS에 저장하도록 합니다.
D. Application Load Balancer를 구성하여 요청을 두 서버로 보냅니다. 각 문서를 올바른 서버에서 반환하도록 합니다.
(c)

6.
회사는 온프레미스 네트워크 부착 스토리지에 NFS를 사용하여 큰 비디오 파일을 저장하고 있습니다. 각 비디오 파일의 크기는 1MB에서 500GB까지 다양합니다. 총 스토리지 용량은 70TB이며 더 이상 증가하지 않습니다. 회사는 비디오 파일을 가능한 빨리 Amazon S3로 마이그레이션해야 하며 네트워크 대역폭 사용을 최소화해야 합니다.
이 요구사항을 충족하는 솔루션은 무엇입니까?

A. S3 버킷을 생성합니다. S3 버킷에 쓸 수 있는 권한을 가진 IAM 역할을 생성합니다. AWS CLI를 사용하여 모든 파일을 로컬에서 S3 버킷으로 복사합니다.
B. AWS Snowball Edge 작업을 생성합니다. 온프레미스에 Snowball Edge 장치를 받습니다. Snowball Edge 클라이언트를 사용하여 데이터를 장치로 전송합니다. 장치를 반환하여 AWS가 데이터를 Amazon S3로 가져오도록 합니다.
C. 온프레미스에 S3 파일 게이트웨이를 배포합니다. S3 파일 게이트웨이에 연결하기 위한 공용 서비스 엔드포인트를 생성합니다. S3 버킷을 생성합니다. S3 파일 게이트웨이에 새로운 NFS 파일 공유를 생성합니다. 새 파일 공유를 S3 버킷에 연결합니다. 기존 NFS 파일 공유에서 S3 파일 게이트웨이로 데이터를 전송합니다.
D. 온프레미스 네트워크와 AWS 간에 AWS Direct Connect 연결을 설정합니다. 온프레미스에 S3 파일 게이트웨이를 배포합니다. S3 파일 게이트웨이에 연결하기 위한 공용 가상 인터페이스(VIF)를 생성합니다. S3 버킷을 생성합니다. S3 파일 게이트웨이에 새로운 NFS 파일 공유를 생성합니다. 새 파일 공유를 S3 버킷에 연결합니다. 기존 NFS 파일 공유에서 S3 파일 게이트웨이로 데이터를 전송합니다.