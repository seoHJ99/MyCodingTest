앙상블
여러 개별 모델을 묶어서 최적의 모델을 만드는 머신러닝 과정.
Bagging 과 Boosting 으로 이뤄짐.
1. Bagging
각 시행이 서로 영향을 미치지 않음. 독립시행.
2. Boosting
이전 모델 학습이 다음 모델 학습에 영향을 끼치는 방법.

XGBoost 알고리즘.
부스팅의 한 방법.

모델 평가
Validation 데이터와 Test 데이터로 모델을 평가함.

혼동행렬 - 분류에 사용.
세로열이 실제, 가로열이 예측치를 의미.
------------------------------
            예측
실  (참 긍정)   (거짓 부정) 
제  (거짓 긍정) (참 부정)
--------------------------------

첫 값이 참, 즉, 실제값이 참인 값들은 분류가 옳바르게 됨을 의미.
(실제 값이 참인 개수) / (전체 값) = 정확도

정밀도 - 얼마나 잘 맞추는가? - 즉, 예측치가 참일때 얼마나 잘 맞는가?
(예측치와 실제값이 모두 긍정인 개수) / (예측치가 긍정인 개수) = 정밀도

재현율 - 얼마나 잘 예측하는가? 즉, 실제로 참일때 얼마나 예측이 맞았는가?
(실제값과 예측값이 모두 참, 긍정인 개수) / (실제값이 참인 개수) = 재현율

모델 생성 -> 엔드포인트 설정에서 모델과 연결 -> 엔드포인트 생성 -> 엔드포인트 호출시 모델 사용
엔드포인트는 실시간 모델이 필요함.
배치는 딱히 필요 없음.

epoch 와 round-num 은 같은 의미.

----------------------------------------
생성형 ai
자연어 처리.
기존 ai 들은 예측까지가 한계였으나, 생성형 ai 는 예측을 바탕으로 생성까지 가능.
인터넷에서 정제되지 않은 데이터로 학습. 데이터가 많음.
파라미터 개수가 많음.
레이블이 없는 데이터(비지도 학습) -> 훈련 -> 파운데이션 모델(목적이 정해지지 않음) -> 적용
ML 모델과 달리 목적이 없음.
ML에 비해 전문성이 떨어지는 모습을 보임.
환각 현상이 존재. 데이터만 넣으면 안되고, 이에 맞는 지침을 정해줘야함(프롬프트).
멀티모달 : 입력값과 출력값 형식이 다른 것.(입력-텍스트, 출력-그림 등)

Transformer 모델
자연어를 이해하고 생성하는 모델로 나뉨.
Encoder 와 Decoder

파인튜닝
목적에 맞게 미세조정하는 것.

백터
데이터를 컴퓨터가 이해할수 있도록 숫자로 바꿈.
이를 이용해서 의미가 유사한 데이터를 찾을수 있음. 다른 데이터와의 숫자 차이로.
임베딩 : 데이터를 백터로 저장하는 것.

RAG
별도의 데이터 모음.
생성형 AI 에게 별도의 데이터를 학습시키고자 할때, 학습시킬 데이터를 모아둔 것.

Top P
누적확률.
답변을 여러개 만들고, 그중 답변 확률이 높은 것부터 더해서 Top P 값까지 값을 산출함.

Temperature
0이면 항상 같은 값을 나오고, 값이 높을수록 같은 질문에도 항상 다른 답변이 나옴.

-----------------------------------------------------
아마존 Q
아마존 공식문서를 참조하여 aws 관련 서비스 답변을 하는 아마존 서비스

-----------------------------------------------------
Bedrock
아마존에서 중계해주는 ai. 타 회사에서 만들어둔 ai 를 사용하는 기능.

Knowledge Base
RAG 만드는 aws 기능.
s3 의 데이터를 이용해 만든다.

Agent
자동으로 프롬프트를 작성.
action group 은 api 를 이용해서 람다를 실행.
LLM에서 동작. Knowledge Base 는 옵션.